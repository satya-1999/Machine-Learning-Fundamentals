{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e828da",
   "metadata": {},
   "source": [
    "# Importing Libraries:\n",
    "- With from sklearn import datasets, we're specifically importing the datasets submodule from scikit-learn. This means we can directly access the functionalities provided by the datasets submodule without needing to prefix them.\n",
    "- With from sklearn.preprocessing import StandardScaler, we're specifically importing the StandardScaler class from the preprocessing submodule. This means we can directly access the StandardScaler class without needing to prefix it. \n",
    "- SVC from sklearn.svm is the Support Vector Classification implementation for classification tasks.\n",
    "- With from sklearn.metrics import classification_report, we're specifically importing the classification_report function from the metrics submodule. This allows us to directly use the classification_report function without needing to prefix it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3420d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0cae3",
   "metadata": {},
   "source": [
    "# Iris Dataset:\n",
    "The Iris dataset is a classic dataset in the field of machine learning and statistics. It contains measurements of iris flowers from three different species: Setosa, Versicolor, and Virginica. Each flower is characterized by four features: sepal length, sepal width, petal length, and petal width. The dataset consists of 150 samples, with 50 samples per species. It's commonly used for tasks like classification and clustering algorithms, as well as for teaching and learning purposes due to its simplicity and well-defined structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd8ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310239c8",
   "metadata": {},
   "source": [
    "# Standard scaler:\n",
    "A preprocessing method called StandardScaler is used in machine learning to standardize a dataset's characteristics. The data is transformed to have a mean of 0 and a standard deviation of 1. Another name for this procedure is Z-score normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a0e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there are no missing values in the Iris dataset, so no handling is needed.\n",
    "# There are even no categorical target variables in the Iris dataset, so no encoding is needed.\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f487d50",
   "metadata": {},
   "source": [
    "# Modeling:\n",
    "An SVM classifier with a 'Linear' kernel was chosen for the classification task.\n",
    "The dataset was split into training and testing sets, with 80% of the data used for\n",
    "training and 20% for testing.\n",
    "The 'Linear' kernel was selected based on its suitability for the problem at hand,\n",
    "but other kernels like 'poly', 'rbf', and 'sigmoid' could also be explored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fba6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b54df8",
   "metadata": {},
   "source": [
    "# K-Fold cross validation:\n",
    "It is a widely used technique in machine learning for assessing the performance of a model. The basic idea behind k-fold cross-validation is to partition the dataset into k subsets, or \"folds,\" of approximately equal size. Then, the model is trained and evaluated k times, each time using a different fold as the validation set and the remaining folds as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781fb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-fold cross-validation\n",
    "k = 5  # Number of folds\n",
    "cv_scores = cross_val_score(svm_classifier, X_scaled, y, cv=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398ec36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 1.         0.93333333 0.93333333 1.        ]\n",
      "Average accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891d709",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "Performance metrics such as accuracy, precision, recall, and F1-score were\n",
    "computed to evaluate the models effectiveness.\n",
    "The percentage of correctly classified cases is measured by accuracy, while the models' capacity to catch positive examples and make accurate positive predictions is indicated by precision, recall, and F1-score.\n",
    "The obtained metrics indicate the models performance on the test set and its\n",
    "overall effectiveness in classifying iris species based on their measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2361b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on the whole dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       0.98      0.92      0.95        50\n",
      "   virginica       0.92      0.98      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report on the whole dataset\n",
    "svm_classifier.fit(X_scaled, y)\n",
    "y_pred = svm_classifier.predict(X_scaled)\n",
    "report = classification_report(y, y_pred, target_names=iris.target_names)\n",
    "print(\"Classification Report on the whole dataset:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab24bc",
   "metadata": {},
   "source": [
    "# Output Explanation:\n",
    "\n",
    "- Precision: Precision assesses the accuracy of positive predictions. It represents the proportion of true positive predictions to the total number of positive predictions made by the model for each class. For \"setosa,\" precision is perfect at 1.00, signifying that all model predictions for \"setosa\" are accurate. \"Versicolor\" boasts a precision of 0.98, indicating 98% accuracy, while \"virginica\" achieves a precision of 0.92, meaning 92% accuracy.\n",
    "- Recall: Recall gauges the model's capability to correctly recognize instances of a class. It is the ratio of true positive predictions to the total number of actual instances for each class. \"Setosa\" attains a recall of 1.00, reflecting accurate identification of all \"setosa\" instances. \"Versicolor\" achieves a recall of 0.92, accurately identifying 92% of \"versicolor\" instances, and \"virginica\" records a recall of 0.98, accurately identifying 98% of \"virginica\" instances.\n",
    "- F1-score: The F1-score, a harmonic mean of precision and recall, offers a balanced assessment of both metrics. It serves as a compromise between precision and recall. \"Setosa\" scores a perfect F1-score of 1.00, while \"versicolor\" and \"virginica\" both achieve F1-scores of 0.95.\n",
    "- Support: Support denotes the actual occurrences of each class in the dataset. The support value for each class (\"setosa,\" \"versicolor,\" \"virginica\") is 50, indicating 50 instances of each class in the dataset.\n",
    "- Accuracy: Accuracy measures the overall correctness of the model's predictions, representing the ratio of correct predictions to the total predictions. The model achieves an overall accuracy of 97%, correctly predicting the class for 97% of instances in the dataset.\n",
    "- Macro Average: The macro average calculates the average precision, recall, and F1-score across all classes, disregarding class imbalance.\n",
    "- Weighted Average: The weighted average calculates the average precision, recall, and F1-score across all classes, taking into account class imbalance by assigning weights based on each class's support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
